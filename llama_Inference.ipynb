{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "# import ollama\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sorted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_text(code):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        names = set()\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Name):\n",
    "                names.add(node.id)\n",
    "            elif isinstance(node, ast.ClassDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.Constant):\n",
    "                names.add(node.value)\n",
    "        comments = re.findall(r'#.*', code)\n",
    "        user_text = names.union(comments)\n",
    "        return ''.join([x for x in user_text if len(x) > 4])\n",
    "    except Exception as e:\n",
    "        return code.replace('\\n','. ').replace('    ', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Disable parallelism in tokenizers to avoid warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "# import ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "df = pd.read_csv('data/sorted_data.csv')\n",
    "\n",
    "# split the code into text using astor\n",
    "def extract_user_text(code):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        names = set()\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, ast.Name):\n",
    "                names.add(node.id)\n",
    "            elif isinstance(node, ast.ClassDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                names.add(node.name)\n",
    "            elif isinstance(node, ast.Constant):\n",
    "                names.add(node.value)\n",
    "        comments = re.findall(r'#.*', code)\n",
    "        user_text = names.union(comments)\n",
    "        return ''.join([x for x in user_text if len(x) > 4])\n",
    "    except Exception as e:\n",
    "        return code.replace('\\n','. ').replace('    ', ' ')\n",
    "\n",
    "russian_regex = re.compile(r'[а-яА-ЯёЁ]')\n",
    "english_regex = re.compile(r'[a-zA-Z]')\n",
    "\n",
    "translate_tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "translate_model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "\n",
    "def translate_russian_to_english(text_to_translate):\n",
    "    if type(text_to_translate) != str:\n",
    "        try: \n",
    "            text_to_translate = ''.join(text_to_translate.split())\n",
    "        except Exception as e:\n",
    "            print(f\"Error while translating Russian to English: {e}\")\n",
    "            return text_to_translate\n",
    "    words = text_to_translate.split()\n",
    "    translated_words = []\n",
    "    for word in words:\n",
    "        if russian_regex.search(word):\n",
    "            input_tokens = translate_tokenizer.encode(word, return_tensors=\"pt\")\n",
    "            output_tokens = translate_model.generate(input_tokens)\n",
    "            translated_word = translate_tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
    "            translated_words.append(translated_word)\n",
    "        else:\n",
    "            translated_words.append(word)\n",
    "    translated_text = ' '.join(translated_words)\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "guard_model = OllamaLLM(model=\"xe/llamaguard3:latest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_full(prompts):\n",
    "    processed_prompts = [translate_russian_to_english(extract_user_text(prompt)) for prompt in prompts]\n",
    "    return [guard_model.invoke(prompt) for prompt in processed_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100  # Adjust the batch size based on your memory and performance requirements\n",
    "labels = []\n",
    "\n",
    "for start in tqdm(range(0, len(df), batch_size)):\n",
    "    end = start + batch_size\n",
    "    batch_prompts = df['Prompt'][start:end]\n",
    "    batch_predictions = pipe_full(batch_prompts)\n",
    "    labels.extend(batch_predictions)\n",
    "    \n",
    "    if (start // batch_size + 1) % 5 == 0:  # Save every 500 rows (5 batches of 100)\n",
    "        df.loc[:len(labels)-1, 'Label'] = labels\n",
    "        df.to_csv('data/result_with_labels.csv', index=False)\n",
    "        print(f\"Data saved to 'data/result_with_labels.csv' after processing {len(labels)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label'] = labels\n",
    "df.to_csv('data/result_with_labels.csv', index=False)\n",
    "print(\"Final data saved to 'data/result_with_labels.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
